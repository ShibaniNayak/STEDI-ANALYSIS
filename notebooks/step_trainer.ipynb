{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%help",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.7 \n",
					"output_type": "stream"
				},
				{
					"output_type": "display_data",
					"data": {
						"text/markdown": "\n# Available Magic Commands\n\n## Sessions Magic\n\n----\n    %help                             Return a list of descriptions and input types for all magic commands. \n    %profile            String        Specify a profile in your aws configuration to use as the credentials provider.\n    %region             String        Specify the AWS region in which to initialize a session. \n                                      Default from ~/.aws/config on Linux or macOS, \n                                      or C:\\Users\\ USERNAME \\.aws\\config\" on Windows.\n    %idle_timeout       Int           The number of minutes of inactivity after which a session will timeout. \n                                      Default: 2880 minutes (48 hours).\n    %timeout            Int           The number of minutes after which a session will timeout. \n                                      Default: 2880 minutes (48 hours).\n    %session_id_prefix  String        Define a String that will precede all session IDs in the format \n                                      [session_id_prefix]-[session_id]. If a session ID is not provided,\n                                      a random UUID will be generated.\n    %status                           Returns the status of the current Glue session including its duration, \n                                      configuration and executing user / role.\n    %session_id                       Returns the session ID for the running session.\n    %list_sessions                    Lists all currently running sessions by ID.\n    %stop_session                     Stops the current session.\n    %glue_version       String        The version of Glue to be used by this session. \n                                      Currently, the only valid options are 2.0, 3.0 and 4.0. \n                                      Default: 2.0.\n    %reconnect          String        Specify a live session ID to switch/reconnect to the sessions.\n----\n\n## Selecting Session Types\n\n----\n    %streaming          String        Sets the session type to Glue Streaming.\n    %etl                String        Sets the session type to Glue ETL.\n    %session_type       String        Specify a session_type to be used. Supported values: streaming and etl.\n----\n\n## Glue Config Magic \n*(common across all session types)*\n\n----\n\n    %%configure         Dictionary    A json-formatted dictionary consisting of all configuration parameters for \n                                      a session. Each parameter can be specified here or through individual magics.\n    %iam_role           String        Specify an IAM role ARN to execute your session with.\n                                      Default from ~/.aws/config on Linux or macOS, \n                                      or C:\\Users\\%USERNAME%\\.aws\\config` on Windows.\n    %number_of_workers  int           The number of workers of a defined worker_type that are allocated \n                                      when a session runs.\n                                      Default: 5.\n    %additional_python_modules  List  Comma separated list of additional Python modules to include in your cluster \n                                      (can be from Pypi or S3).\n    %%tags        Dictionary          Specify a json-formatted dictionary consisting of tags to use in the session.\n    \n    %%assume_role Dictionary, String  Specify a json-formatted dictionary or an IAM role ARN string to create a session \n                                      for cross account access.\n                                      E.g. {valid arn}\n                                      %%assume_role \n                                      'arn:aws:iam::XXXXXXXXXXXX:role/AWSGlueServiceRole' \n                                      E.g. {credentials}\n                                      %%assume_role\n                                      {\n                                            \"aws_access_key_id\" : \"XXXXXXXXXXXX\",\n                                            \"aws_secret_access_key\" : \"XXXXXXXXXXXX\",\n                                            \"aws_session_token\" : \"XXXXXXXXXXXX\"\n                                       }\n----\n\n                                      \n## Magic for Spark Sessions (ETL & Streaming)\n\n----\n    %worker_type        String        Set the type of instances the session will use as workers. \n    %connections        List          Specify a comma separated list of connections to use in the session.\n    %extra_py_files     List          Comma separated list of additional Python files From S3.\n    %extra_jars         List          Comma separated list of additional Jars to include in the cluster.\n    %spark_conf         String        Specify custom spark configurations for your session. \n                                      E.g. %spark_conf spark.serializer=org.apache.spark.serializer.KryoSerializer\n----\n\n## Action Magic\n\n----\n\n    %%sql               String        Run SQL code. All lines after the initial %%sql magic will be passed\n                                      as part of the SQL code.  \n    %matplot      Matplotlib figure   Visualize your data using the matplotlib library.\n                                      E.g. \n                                      import matplotlib.pyplot as plt\n                                      # Set X-axis and Y-axis values\n                                      x = [5, 2, 8, 4, 9]\n                                      y = [10, 4, 8, 5, 2]\n                                      # Create a bar chart \n                                      plt.bar(x, y) \n                                      # Show the plot\n                                      %matplot plt    \n    %plotly            Plotly figure  Visualize your data using the plotly library.\n                                      E.g.\n                                      import plotly.express as px\n                                      #Create a graphical figure\n                                      fig = px.line(x=[\"a\",\"b\",\"c\"], y=[1,3,2], title=\"sample figure\")\n                                      #Show the figure\n                                      %plotly fig\n\n  \n                \n----\n\n"
					},
					"metadata": {}
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 5.0\n%worker_type G.1X\n%number_of_workers 5\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Current idle_timeout is None minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 5.0\nPrevious worker type: None\nSetting new worker type to: G.1X\nPrevious number of workers: None\nSetting new number of workers to: 5\nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 5\nIdle Timeout: 2880\nSession ID: bf62ce0b-468f-416f-ae99-f88db4c6153d\nApplying the following default arguments:\n--glue_kernel_version 1.0.7\n--enable-glue-datacatalog true\nWaiting for session bf62ce0b-468f-416f-ae99-f88db4c6153d to get into ready status...\nSession bf62ce0b-468f-416f-ae99-f88db4c6153d has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Create a DynamicFrame from a table in the AWS Glue Data Catalog and display its schema\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "from awsglue.dynamicframe import DynamicFrame\n\nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)\n\nstep_trainer_dyf = glueContext.create_dynamic_frame.from_catalog(database='default', table_name='step_trainer')\nstep_trainer=step_trainer_dyf.toDF()\naccelerometer_trusted_dyf=glueContext.create_dynamic_frame.from_catalog(database='default', table_name='accelerometer_trusted_table')\naccelerometer_trusted_df = accelerometer_trusted_dyf.toDF()\n\n\ncustomer_curated_dyf = glueContext.create_dynamic_frame.from_catalog(database='default', table_name='customer_curated_table')\ncustomer_curated_df = customer_curated_dyf.toDF()\nstep_trainer_trusted= step_trainer.join(customer_curated_df,step_trainer.serialNumber==customer_curated_df.serialNumber,\"leftsemi\" )\nmachine_learning_curated = step_trainer_trusted.join(accelerometer_trusted_df,accelerometer_trusted_df.timestamp== step_trainer_trusted.sensorReadingTime,\"inner\")\n\nstep_trainer_trusted_dyf = DynamicFrame.fromDF(\n    step_trainer_trusted,\n    glueContext,\n    \"step_trainer_trusted_dyf\"\n)\nmachine_learning_curated_dyf = DynamicFrame.fromDF(\nmachine_learning_curated,\nglueContext,\n\"machine_learning_curated_dyf\"\n)\nprint(accelerometer_trusted_df.count())\nprint(machine_learning_curated.count())\naccelerometer_trusted_df.printSchema()\nstep_trainer.printSchema()\ncustomer_curated_df.printSchema()",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "40981\n43681\nroot\n |-- user: string (nullable = true)\n |-- timestamp: long (nullable = true)\n |-- x: double (nullable = true)\n |-- y: double (nullable = true)\n |-- z: double (nullable = true)\n\nroot\n |-- sensorReadingTime: long (nullable = true)\n |-- serialNumber: string (nullable = true)\n |-- distanceFromObject: integer (nullable = true)\n\nroot\n |-- customerName: string (nullable = true)\n |-- email: string (nullable = true)\n |-- phone: string (nullable = true)\n |-- birthDay: string (nullable = true)\n |-- serialNumber: string (nullable = true)\n |-- registrationDate: long (nullable = true)\n |-- lastUpdateDate: long (nullable = true)\n |-- shareWithResearchAsOfDate: long (nullable = true)\n |-- shareWithPublicAsOfDate: long (nullable = true)\n |-- shareWithFriendsAsOfDate: long (nullable = true)\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Convert the DynamicFrame to a Spark DataFrame and display a sample of the data\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "glueContext.write_dynamic_frame.from_options(\n    frame = step_trainer_trusted_dyf,\n    connection_type=\"s3\",\n    connection_options={\n        \"path\": \"s3://step-trainer/trusted/\",\n        \"partitionKeys\": []\n    },\n    format=\"json\"\n)\n\nglueContext.write_dynamic_frame.from_options(\nframe = machine_learning_curated_dyf,\n    connection_type=\"s3\",\n    connection_options={\n        \"path\": \"s3://step-trainer/machine_learning/\",\n        \"partitionKeys\": []\n    },\n    format=\"json\"\n\n)\nmachine_learning_curated_dyf.printSchema()",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n|-- sensorReadingTime: long\n|-- serialNumber: string\n|-- distanceFromObject: int\n|-- user: string\n|-- timestamp: long\n|-- x: double\n|-- y: double\n|-- z: double\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "%%sql\nCREATE EXTERNAL TABLE IF NOT EXISTS step_trainer_trusted(\nsensorReadingTime long,\nserialNumber string,\ndistanceFromObject integer\n)\nROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'\nLOCATION 's3://step-trainer/trusted/'\nTBLPROPERTIES ('encrypted'='false')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Visualize data with matplotlib\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%%sql\nCREATE EXTERNAL TABLE IF NOT EXISTS machine_learning_curated(\nsensorReadingTime long,\nserialNumber string,\ndistanceFromObject integer,\nuser string,\ntimestamp long,\nx double,\ny double,\nz double\n)\nROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'\nLOCATION 's3://step-trainer/machine_learning/'\nTBLPROPERTIES ('encrypted'='false')",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 10,
			"outputs": [
				{
					"name": "stdout",
					"text": "++\n||\n++\n++\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Write the data in the DynamicFrame to a location in Amazon S3 and a table for it in the AWS Glue Data Catalog\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": null,
			"outputs": []
		}
	]
}